[DEFAULT]
# Log directory for all logging related to this model
log_dir=/tmp/experiments/logs

# experiment_dir -- used to define on local filesystem what
# directory one would like to use to save experiment specific
# configuration files / datasets / etc.
experiment_dir = ./experiments/1


# Flow files -> this implementation assumes Argus file formats for flow collector format
# This can be extended in the modules to support other flow formats as well
flow_files = /home/ed/Documents/data/ctu-13/capture20110810.binetflow

# Number of flows to process from each flow file
num_flows = 50000

# window size -- this is used to determine the size of the windows
# that one would like to create from the data
window_size = 25

# num_windows -- the total number of windows one would like to 
# create using the training data; it is important to understand
# that the numbers of windows and size of the windows are dependent
# on the overall size of the training data set in that if we
# the max number of flows and windows we could create would be 
# (window_size / len(training_data) modulo some number of left over flows.
num_windows = 10000

# exp_dataset_dir -- this variable is used to define an output directory
# for the dataset subset that is generated per experiment
# this is useful for experimental reproducibility
exp_dataset_dir = ./dataset
[TRAIN]

# batch_size - batch size to use for training the model
batch_size = 128

# embedding_size -- size of the embedding layer 
embedding_size = 128

# skip_window -- size of window of tokens to sample to the left and right of the
# trainnig data
skip_window = 1

# over_sample_rate -- number of times to reuse next step input to generate a label
over_sample_rate = 2

# num_negative_examples -- number of negative samples to use when utilizing SGNS
num_negative_examples = 64

# validation_size -- number of samples to use for similarity measure for measuring
# "accuracy" of the model
validation_size = 16

# validation_window 
validation_window = 100

[TEST]